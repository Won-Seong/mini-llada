# ğŸ‡°ğŸ‡· Mini-LLaDA: Korean Small Language Diffusion Model

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-Transformers-yellow)
![License](https://img.shields.io/badge/License-Apache_2.0-blue)

## ğŸ“– Introduction
**Mini-LLaDA**ëŠ” ê¸°ì¡´ì˜ Autoregressive(GPT ë°©ì‹) ìƒì„± ëª¨ë¸ì´ ì•„ë‹Œ, **Masked Diffusion** ë°©ì‹ì„ ì ìš©í•œ 0.3B ê·œëª¨ì˜ í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)ì…ë‹ˆë‹¤.

ë³¸ í”„ë¡œì íŠ¸ëŠ” [LLaDA: Large Language Diffusion Models](https://arxiv.org/abs/2502.09992) ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ì‚¬ì „ í•™ìŠµëœ Encoder ê¸°ë°˜ ëª¨ë¸ì¸ **RoBERTa**ë¥¼ Diffusion Generatorë¡œ ì „í™˜(Upcycling)í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„± ëŠ¥ë ¥ì„ ë¶€ì—¬í•˜ëŠ” ì‹¤í—˜ì ì¸ ì—°êµ¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## âœ¨ Key Features
- **Generative Adaptation:** íŒë³„(Discriminative) ëª¨ë¸ì¸ RoBERTaë¥¼ ìƒì„±(Generative) ëª¨ë¸ë¡œ ì„±ê³µì ìœ¼ë¡œ ì „í™˜.
- **Efficient SLM (0.3B):** 3ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¡œ êµ¬ì„±ëœ ê²½ëŸ‰ ëª¨ë¸ë¡œ, ì œí•œëœ ì»´í“¨íŒ… ìì›ì—ì„œì˜ í•™ìŠµ ë° ì¶”ë¡  ìµœì í™”.
- **Custom Diffusion Sampler:**
  - **Monotonic Unmasking:** ìƒì„±ëœ í† í°ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´, ì´ë¯¸ ì˜ˆì¸¡ëœ í† í°ì„ ë³´ì¡´í•˜ëŠ” ë‹¨ì¡° ì–¸ë§ˆìŠ¤í‚¹ ë¡œì§ êµ¬í˜„.
  - **Low-confidence Remasking:** ì‹ ë¢°ë„ê°€ ë‚®ì€ í† í°ì„ ì¬ì¡°ì •í•˜ì—¬ 0.3B ëª¨ë¸ì˜ ìƒì„± í’ˆì§ˆì„ ë³´ì™„.
- **EOS-Aware Training:** SFT ë‹¨ê³„ì—ì„œ EOS í† í°ì„ ê°•ì œ íŒ¨ë”©(Mask=1)í•˜ì—¬ í•™ìŠµì‹œí‚´ìœ¼ë¡œì¨, Diffusion ëª¨ë¸ì´ ë¬¸ì¥ ì¢…ë£Œ ì‹œì ì„ ìŠ¤ìŠ¤ë¡œ ì œì–´í•˜ë„ë¡ ì„¤ê³„.

## ğŸ—ï¸ Architecture & Methodology
### 1. Model Structure
- **Backbone:** `klue/roberta-small` (or similar BERT-based models)
- **Framework:** Continuous Pre-training â†’ Supervised Fine-Tuning (SFT)
- **Mechanism:** Bidirectional Contextë¥¼ í™œìš©í•œ Masked Diffusion Process ($t=1 \to t=0$)

### 2. Training Strategy
- **Pre-training:** Wikipedia ë° News Corpusë¥¼ í™œìš©í•˜ì—¬ Diffusion í”„ë¡œì„¸ìŠ¤ ì ì‘ (Adaptation).
- **SFT (Supervised Fine-Tuning):** Q&A ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ Instruction Following ëŠ¥ë ¥ ì£¼ì….
- **Length Control:** EOS í† í° ë¹„ì¤‘ì´ ë†’ì€ ë°ì´í„°ì˜ í¸í–¥ì„ ì œì–´í•˜ê¸° ìœ„í•´ ì¶”ë¡  ë‹¨ê³„ì—ì„œì˜ Logit Suppression ê¸°ë²• ì ìš©.

## ğŸ“Š Experiments & Data
Base Data: wikimedia/wikipedia (Korean subset), AI-Hub Text Data.

SFT Data: Custom QA Datasets.

Evaluation: ëª¨ë¸ì˜ í¬ê¸°(0.3B) í•œê³„ë¡œ ì¸í•´ ë³µì¡í•œ ì¶”ë¡ ë³´ë‹¤ëŠ” ë¬¸ì¥ ì™„ì„±ë„(Fluency)ì™€ ë¬¸ë²•ì  ì •í™•ì„±(Grammatical Correctness), ê·¸ë¦¬ê³  Diffusion ê¸°ë°˜ ìƒì„± ê°€ëŠ¥ì„± ê²€ì¦ì— ì´ˆì ì„ ë§ì¶¤.

## âš ï¸ Limitations
Model Capacity: 0.3Bì˜ ì‘ì€ íŒŒë¼ë¯¸í„° ìˆ˜ë¡œ ì¸í•´ ë³µì¡í•œ ë…¼ë¦¬ ì¶”ë¡ ì´ë‚˜ ê¸´ ë¬¸ë§¥ ìœ ì§€ì—ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.

Inference Speed: Diffusion íŠ¹ì„±ìƒ Autoregressive ëª¨ë¸ ëŒ€ë¹„ ìƒì„± ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (Iterative Denoising).

EOS Bias: í•™ìŠµ ë°ì´í„°ì˜ íŒ¨ë”© ë¹„ì¤‘ìœ¼ë¡œ ì¸í•´ ì¶”ë¡  ì‹œ EOS í† í° ìƒì„± ê²½í–¥ì´ ê°•í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” Sampler íŒŒë¼ë¯¸í„°ë¡œ ì œì–´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“š References
This project is heavily inspired by the following paper:

@article{nie2024llada,
  title={LLaDA: Large Language Diffusion Models},
  author={Nie, Shen and Zhu, Fengqi and others},
  journal={arXiv preprint arXiv:2502.09992},
  year={2024}
}

## ğŸ‘¨â€ğŸ’» Author
[Sungwon Kim] - Project Lead & Implementation
Interest: LLM, Diffusion Models, NLP
